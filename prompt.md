Je veux implementer un protocole de transport pur (insistance sur transport pur) basé sur QUIC notamment quic-go. le protocole permettra à un client de communiquer ou de recevoir des données au niveau du transport de plusieurs sources contrairement à quic qui ne connecte un client qu'a un seul serveur à la fois on fera du multipath.

premierement coté client, le developpeur sait qu'il a une interface identique à QUIC, il fait un dial puis un openstreamsync ou un acceptstream comme normalement avec kwik. le dial renvera un objet session sur lequel il poura appliquer les methodes d'ouverture ou d'acceptation de flux, celles ci retournent un flux sur lequel il fera les opérations usuelles sur les flux coté serveur le developpeur a un listen à partir duquel il ecoute ce listen de creer une session une fois la session obtenue il poura executer les methodes d'acceptation ou d'ouverure de flux comme pour le client. ici ces deux elements sont bien des session et stream au sens de KWIK c'est à dire, au sens client une session est une facade, une simple amélioartion de QUIC mais à l'interieur elle est tout une aggregat complexe et cohérente de connections QUIC distincte et une gestion fine de flux pour un plan de données et un palen de controle interne. coté serveur, c'est également de facade une simple amélioration de l'interface de QUIC mais à l'interieur une connection QUIC complexe avec une gestion de plan de controle et de plan de données. quand un on fait un stream write coté serveur ces données transitent par le plan de données du protocole, et quand on fait un stream read coté serveur ces données proviennent du plan de données egalement. de meme coté client quand on fait un stream read, ces données proviennet du plan de données sauf que pour la session cliente comme elle est connecté à plusieurs sessions serveurs, celle ci aggrege les données en provenance de plusieurs plan de données. d'ou la nécessité d'une gestion éficace des chemins de données, d'un bon réassemblage des flux entrants d'un bon sequencage des flux sortant, et pour de meilleures performances on a dont besoin de representations de trames et de paquets de données et d'une gestion des espaces de numérotation de paquets par chemin. pour le plan de controle interne, la session cliente ne le voit que de maniere interne, l'interface publique l'isole et n'offre aucun moyen d'intéragir avec lui. par contre la session serveur peut offir des moyens d'interagir avec le plan controle, je vois le cas d'ajout et de retrait de chemins, de recuperation des chemins actifs et des chemins morts et de recupération de tous les chemins depuis le debut de la session. les commandes d'ajout et de retrait de chemins passent justement par le plan de controle et vont à la session cliente mais seront interprété et executé en interne pour les besoins du transport et non du developpeur donc il ne les vera jamais coté client. le plan de controle servira egalement a la session cliente de s'authentifier sur une session serveur, de maniere interne quand on fera le dial quic pour creer un path vers un nouveau serveur, on ouvira ce flux la pour s'authentifier puis une fois fait on ouvrira le/les flux du plan de données selon le besoin biensur. je dois faire la distinction ici entre les chemins car quand le client fait son dial sur la session KWIK, il n'a que l'adresse du serveur principal donc c'est le chemin principal, sur ce dial en realité il fera en interne un dial QUIC puis une ouverture du flux de plan controle puis un identifiant unique de session sera attribué au client via ce plan de controle et ce chemin sera marqué comme principal (c'est le chimin par defaut) des deux coté et lorque le client fera un openStrem ou openStreamSync sur sa session, en interne, la session identifiera ce chemin par defaut et ouvrira un nouveau flux de données sur cette connection QUIC (chemin) et le strem ouvert sera lié au strema KWIK que le developpeur voit, ce qui lui permettra d'ouvrir plusieurs flux de données s'il le désire on peut meme optimiser cela en faisant en sorte que l'ouvertur de stream sur session KWIK fasse transiter des control de commande sur le plan de control pour notifier à la session de creer de nouvex streams avec les identifiants sans pour autant provquer la creation de nouveau flux QUIC reels et lorque ces flux sont utilisé pour faire de nouveaux writes ou reads on peut simplement utiliser un seul flux QUIC reel pour desservir ces différents flux logiques et comme on a des trames et des paquets, ceux ci nous serviraient à identifier et transporter les données en provenance et a destination de flux logiques vus par le developpeurs avec leurs identifiants de flux logique. en cas de besoin on pourait donc augmenter le nombre de flux QUIC reel ou diminuer automatiquement pour garder les performance on aurait peut etre un flux QUIC pour 3 a 4 flux logiques KWIK biensur il faut un management robuste pour les flux et une gestion efficace de la reconstitution des flux. surtout les offsets dans le flux et aussi le un bon scheduling d'envoie des données des flux. le plan de controle devrait aussi faire quelque chose d'interessant ordonner la transmission brute de paquets non KWIK je m'explique, si mon serveur est un serveur custom qui utilise KWIK et mon client est un client custom qui utilise KWIK comme transport quic devrait lui permetre de dire prend cette donnée, envoie la via tel chemin. le plan de controle envoie la donnée vers le client interne et celui ci identifie le chemin vers lequel le paquet non KWIK doit aller et le fait transiter sur le plan de donnée sur ce chemin en direction du serveur concerné, lui il lira ces données sur le plan de données pourtant elles sont parties du plan de contole d'un autre serveur, ce cas d'usage sera crucial pour la suite. bien pour l'instant, faisons cela


je suis un peu embêté du fait que file transfer accede ditectement aux elements tres internes du protocole comme le proto/control plutot que d'utiliser les possibilité offertes par la session ca n'a pas de sens pour une application externe à mon avis puisque meme le serveur secondaire est un serveur kwik comme le usecase multi-path-demo le montre.


actuellement je constate que le serveur secondaire est capable de faire des ouvertures de stream direct sur la session cliente comme le serveur principal; c'est le comportement actuel, pour les deux, ce comportement doit etre valide uniquement pour le serveur principal. donc je veux que pour le role secondaire tout se passe en interne quand le serverveur secondaire fait une ouverture de flux sur sa session, cela ne doit pas directement aller sur la session cliente publique mais la gestion des chemins doit rester transparente pour le client donc les ouvertures de flux venant des serveurs secondaires c'est a dire des chemins secondaires, doivent etre traitée à l'intérieur de kwik. cela suggere que quand le chemin secondaire va faire une ouverture de flux sur sa connection QUIC interne, elle sera recue coté client en interne par la connection QUIC du chemin mais sera handle à l'interieur de kwik. et les données que les serveurs secondaires vont ecrire dans ces flux devront etre prises par kwik et positionées dans le bon flux kwik et au bon offset. raison pour laquelle il faut une bonne aggregation des flux QUIC entrant sur les flux kwik et une bonne logique de communication quic entre les element interne de kwik coté client et serveur secondaire


le probleme c'est qu'il faut imposer dans ce cas au niveau QUIC pour les flux ouverts sur le serveur secondaire une cadence lecture ecriture peut etre

peux tu lire les logs de mon usecase multi-path-demo dans le dossier logs dans examples? je veux que tu analyse et comprenne bien ces logs du client et des serveurs pour determiner ce qui bloque et ce qui fait en srte que le client tombe sur cette erreur Réponse invalide: invalid character '\x18' looking for beginning of value pourquoi le transport lui donne des données ilisibles? une analyse profonde du code source sera necessaire

voici ce qui devrait se passer:
1- le client envoi sa requete {json request} cette requete est serialisée par le client et envoyée 
   le transport n'interprete pas le contenu d'un write, il fait son travail et le transprte a sa destinantion

2- Le serveur recoit cette requete (le payload que le client a envoyé) il la traite et renvoie sa reponse
   la reponse du serveur egalement un json {reponse serveur} qu'il serialise et envoie egalement
   le transport n'interprete pas de write, il le transporte et l'aggrege pour qu'il soit presenté et lu par le client.

3- le client lit les données qui viennet d'arriver puisqu'elles ne sont pas interprétée, elle arrivent serialisées,
   il doit donc les lire, les deserialiser et ensuite les interpreter car il ne peut obtenir son json qu'apres deserialisation de ce qu'il a lu.

4- Pour la suite on voit que le serveur primaire envoit des données via le stream qu'il a avec le client et qu'il
   envoie des commandes via la session. ces deux element ne se melangent pas. actuellement les commandes
   fonctionnent parfaitement comme on veut. c'est sur les stream envoyée qu'on doit investiguer. le serveur 
   encapsule en json des portion de fichier paires les serialise et les envoie en definissant bien les
   offsets sur le stream jusqu'a ce qu'il ait terminé

5- le serveur secondaire recoit bien les commande les deserialise et les traite bien en envoyant comme le serveur
   des portion de de fichier encapsulées exactement de la meme manier en definisant aussi les offset sur le stream
   par ce qu'il recoit dans sa commande

6- Le client doit lire en boucle ainsi et deserialiser les portions de données encapsulées dans du json que les
   deux sereurs ont envoyés et les écrire dans le fichier de destination

7- il doit envoyer un Ack quand il a tout lu
8- Le serveur doit lire l'Ack et tout terminer.


voila ce que le use case est sensé faire.

Le transport doit parfaitement transporter toute ces données sans se soucier de leur contenu cependant il a ses propres structures de donées qui lui permetent de faire la separation l'identification, l'ordre d'aggregation egalemet. Nous avons des packets qui transportent des trames, et ce sont les trames qui transortent les données, (nous somme ici sur le plan de données).

le transport n'est pas lié au use case car le use case est seulement sensé montrer que le transport fonctionne donc le transport doit etre agnostique des données du usecase

quand on recoit une trame à mon avois il convient de faire comme on le fait depuis en stockant

Chaque StreamData ou doit etre lu distinctement par l'application? si le serveur primaire fait un stream.Write(data1) et que le serveur secondaire fait un stream.Write(data2) ta solution consiste à faire concatener dat1 et data2 ainsi le client lira data1data2 mais nous ne voulons pas cela car on part du principe que les données que nous transportons peuvent etre structurées (et c'est le cas) mais que nous n'avons pas de main mise au niveau transport sur cette structuration, les metadonnées nous donne seulement le flux logique et l'offset dans lequel positionner les données transportées. (je me demande bien pourquoi les treamData ont un champ offset alors qu'il y en a déjà un dans les métadonnées si c'est le même) donc garde la lecture streamData par streamData mais on doit s'assurer de la coherence